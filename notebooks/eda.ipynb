{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# An√†lisi Explorat√≤ria de Dades (EDA) - Dataset de Dem√®ncia\n",
    "\n",
    "Aquest notebook cont√© l'an√†lisi explorat√≤ria del dataset de dem√®ncia, seguint les tasques especificades:\n",
    "\n",
    "1. C√†rrega i inspecci√≥ inicial\n",
    "2. Distribuci√≥ de la variable objectiu\n",
    "3. Estad√≠stiques univariants\n",
    "4. Visualitzacions\n",
    "5. Valors an√≤mals o absents\n",
    "6. An√†lisi bivariada i correlacions\n",
    "7. Resum de descobertes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importaci√≥ de llibreries necess√†ries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configuraci√≥ de visualitzacions\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "%matplotlib inline\n",
    "\n",
    "# Configuraci√≥ per mostrar totes les columnes\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. C√†rrega i Inspecci√≥ Inicial\n",
    "\n",
    "Carreguem el dataset i examinem la seva estructura b√†sica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C√†rrega del dataset\n",
    "# NOTA: Ajusta el path segons la ubicaci√≥ del teu dataset\n",
    "df = pd.read_csv('../data/dementia_dataset.csv')\n",
    "\n",
    "print(\"Dataset carregat correctament!\")\n",
    "print(f\"Dimensions del dataset: {df.shape[0]} files √ó {df.shape[1]} columnes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Primeres files del dataset\n",
    "print(\"Primeres 5 files del dataset:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Informaci√≥ general del dataset\n",
    "print(\"Informaci√≥ general del dataset:\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tipus de dades per columna\n",
    "print(\"\\nTipus de dades:\")\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Noms de les columnes\n",
    "print(\"\\nColumnes del dataset:\")\n",
    "print(df.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Distribuci√≥ de la Variable Objectiu\n",
    "\n",
    "Analitzem la distribuci√≥ de casos amb i sense dem√®ncia per entendre l'equilibri de classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assumim que la variable objectiu es diu 'dementia' o similar\n",
    "# Ajusta el nom de la columna segons el teu dataset\n",
    "target_col = 'dementia'  # Canvia aix√≤ si √©s necessari\n",
    "\n",
    "# Recompte de casos\n",
    "print(\"Distribuci√≥ de la variable objectiu:\")\n",
    "print(\"=\"*50)\n",
    "target_counts = df[target_col].value_counts()\n",
    "print(target_counts)\n",
    "print(\"\\nPercentatges:\")\n",
    "target_percentages = df[target_col].value_counts(normalize=True) * 100\n",
    "print(target_percentages.round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualitzaci√≥ de la distribuci√≥\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Gr√†fic de barres\n",
    "target_counts.plot(kind='bar', ax=axes[0], color=['#2ecc71', '#e74c3c'])\n",
    "axes[0].set_title('Distribuci√≥ de Casos: Dem√®ncia vs No Dem√®ncia', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xlabel('Classe', fontsize=12)\n",
    "axes[0].set_ylabel('Nombre de casos', fontsize=12)\n",
    "axes[0].set_xticklabels(axes[0].get_xticklabels(), rotation=0)\n",
    "\n",
    "# Afegir valors sobre les barres\n",
    "for i, v in enumerate(target_counts):\n",
    "    axes[0].text(i, v + 5, str(v), ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "# Gr√†fic de past√≠s\n",
    "colors = ['#2ecc71', '#e74c3c']\n",
    "axes[1].pie(target_counts, labels=target_counts.index, autopct='%1.1f%%', \n",
    "            startangle=90, colors=colors, textprops={'fontsize': 12, 'fontweight': 'bold'})\n",
    "axes[1].set_title('Proporci√≥ de Classes', fontsize=14, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# C√†lcul del desequilibri de classes\n",
    "imbalance_ratio = target_counts.max() / target_counts.min()\n",
    "print(f\"\\nR√†tio de desequilibri de classes: {imbalance_ratio:.2f}:1\")\n",
    "if imbalance_ratio > 1.5:\n",
    "    print(\"‚ö†Ô∏è ATENCI√ì: El dataset presenta desequilibri de classes. Considera t√®cniques de balanceig.\")\n",
    "else:\n",
    "    print(\"‚úì El dataset est√† relativament equilibrat.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Estad√≠stiques Univariants\n",
    "\n",
    "Analitzem les caracter√≠stiques individuals de cada variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separar variables num√®riques i categ√≤riques\n",
    "numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "categorical_cols = df.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "\n",
    "print(f\"Variables num√®riques ({len(numeric_cols)}): {numeric_cols}\")\n",
    "print(f\"\\nVariables categ√≤riques ({len(categorical_cols)}): {categorical_cols}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Estad√≠stiques de Variables Num√®riques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estad√≠stiques descriptives per variables num√®riques\n",
    "print(\"Estad√≠stiques descriptives de variables num√®riques:\")\n",
    "print(\"=\"*80)\n",
    "df[numeric_cols].describe().round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estad√≠stiques addicionals (asimetria i curtosi)\n",
    "print(\"\\nAsimetria (Skewness) i Curtosi (Kurtosis):\")\n",
    "print(\"=\"*80)\n",
    "stats_df = pd.DataFrame({\n",
    "    'Asimetria': df[numeric_cols].skew(),\n",
    "    'Curtosi': df[numeric_cols].kurtosis()\n",
    "}).round(2)\n",
    "print(stats_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Freq√º√®ncies de Variables Categ√≤riques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freq√º√®ncies per cada variable categ√≤rica\n",
    "for col in categorical_cols:\n",
    "    print(f\"\\nDistribuci√≥ de '{col}':\")\n",
    "    print(\"=\"*50)\n",
    "    freq_table = pd.DataFrame({\n",
    "        'Freq√º√®ncia': df[col].value_counts(),\n",
    "        'Percentatge': df[col].value_counts(normalize=True) * 100\n",
    "    }).round(2)\n",
    "    print(freq_table)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Visualitzacions\n",
    "\n",
    "Creem visualitzacions per entendre millor les distribucions i difer√®ncies entre grups."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Histogrames de Variables Num√®riques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogrames per totes les variables num√®riques\n",
    "n_cols = 3\n",
    "n_rows = (len(numeric_cols) + n_cols - 1) // n_cols\n",
    "\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(15, n_rows * 4))\n",
    "axes = axes.flatten() if n_rows > 1 else [axes]\n",
    "\n",
    "for idx, col in enumerate(numeric_cols):\n",
    "    axes[idx].hist(df[col].dropna(), bins=30, edgecolor='black', alpha=0.7)\n",
    "    axes[idx].set_title(f'Distribuci√≥ de {col}', fontweight='bold')\n",
    "    axes[idx].set_xlabel(col)\n",
    "    axes[idx].set_ylabel('Freq√º√®ncia')\n",
    "    axes[idx].grid(True, alpha=0.3)\n",
    "\n",
    "# Amagar eixos sobrants\n",
    "for idx in range(len(numeric_cols), len(axes)):\n",
    "    axes[idx].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Box Plots per Grup (Dem√®ncia vs No Dem√®ncia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Box plots comparatius\n",
    "# Excloure la variable objectiu de les variables num√®riques\n",
    "numeric_features = [col for col in numeric_cols if col != target_col]\n",
    "\n",
    "n_cols = 3\n",
    "n_rows = (len(numeric_features) + n_cols - 1) // n_cols\n",
    "\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(15, n_rows * 4))\n",
    "axes = axes.flatten() if n_rows > 1 else [axes]\n",
    "\n",
    "for idx, col in enumerate(numeric_features):\n",
    "    sns.boxplot(data=df, x=target_col, y=col, ax=axes[idx], palette='Set2')\n",
    "    axes[idx].set_title(f'{col} per Grup', fontweight='bold')\n",
    "    axes[idx].set_xlabel('Dem√®ncia')\n",
    "    axes[idx].set_ylabel(col)\n",
    "    axes[idx].grid(True, alpha=0.3)\n",
    "\n",
    "# Amagar eixos sobrants\n",
    "for idx in range(len(numeric_features), len(axes)):\n",
    "    axes[idx].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Violin Plots per Variables Clau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Violin plots per variables clau (ajusta segons el teu dataset)\n",
    "# Exemple amb variables t√≠piques d'un dataset de dem√®ncia\n",
    "key_vars = ['age', 'MMSE', 'brain_volume']  # Ajusta aquests noms segons el teu dataset\n",
    "\n",
    "# Filtrar nom√©s les variables que existeixen\n",
    "key_vars_available = [var for var in key_vars if var in df.columns]\n",
    "\n",
    "if key_vars_available:\n",
    "    fig, axes = plt.subplots(1, len(key_vars_available), figsize=(6*len(key_vars_available), 5))\n",
    "    if len(key_vars_available) == 1:\n",
    "        axes = [axes]\n",
    "    \n",
    "    for idx, var in enumerate(key_vars_available):\n",
    "        sns.violinplot(data=df, x=target_col, y=var, ax=axes[idx], palette='muted')\n",
    "        axes[idx].set_title(f'Distribuci√≥ de {var} per Grup', fontweight='bold', fontsize=12)\n",
    "        axes[idx].set_xlabel('Dem√®ncia', fontsize=11)\n",
    "        axes[idx].set_ylabel(var, fontsize=11)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Les variables clau especificades no es troben al dataset. Ajusta 'key_vars'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Scatter Plots (Relacions entre Variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plots per parelles de variables rellevants\n",
    "# Exemple: edat vs MMSE, edat vs volum cerebral, etc.\n",
    "scatter_pairs = [\n",
    "    ('age', 'MMSE'),\n",
    "    ('age', 'brain_volume'),\n",
    "    ('MMSE', 'brain_volume')\n",
    "]  # Ajusta segons el teu dataset\n",
    "\n",
    "# Filtrar parelles que existeixen\n",
    "valid_pairs = [(x, y) for x, y in scatter_pairs if x in df.columns and y in df.columns]\n",
    "\n",
    "if valid_pairs:\n",
    "    n_pairs = len(valid_pairs)\n",
    "    fig, axes = plt.subplots(1, n_pairs, figsize=(6*n_pairs, 5))\n",
    "    if n_pairs == 1:\n",
    "        axes = [axes]\n",
    "    \n",
    "    for idx, (x_var, y_var) in enumerate(valid_pairs):\n",
    "        for group in df[target_col].unique():\n",
    "            mask = df[target_col] == group\n",
    "            axes[idx].scatter(df.loc[mask, x_var], df.loc[mask, y_var], \n",
    "                            label=f'{target_col}={group}', alpha=0.6, s=50)\n",
    "        \n",
    "        axes[idx].set_xlabel(x_var, fontsize=11)\n",
    "        axes[idx].set_ylabel(y_var, fontsize=11)\n",
    "        axes[idx].set_title(f'{x_var} vs {y_var}', fontweight='bold', fontsize=12)\n",
    "        axes[idx].legend()\n",
    "        axes[idx].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Les parelles de variables especificades no es troben al dataset. Ajusta 'scatter_pairs'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5 Gr√†fics de Barres per Variables Categ√≤riques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gr√†fics de barres per variables categ√≤riques segmentades per dem√®ncia\n",
    "for col in categorical_cols:\n",
    "    if col != target_col:\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        \n",
    "        # Crear taula de conting√®ncia\n",
    "        ct = pd.crosstab(df[col], df[target_col], normalize='index') * 100\n",
    "        \n",
    "        ct.plot(kind='bar', stacked=False, color=['#2ecc71', '#e74c3c'])\n",
    "        plt.title(f'Distribuci√≥ de {col} per Grup de Dem√®ncia', fontweight='bold', fontsize=13)\n",
    "        plt.xlabel(col, fontsize=11)\n",
    "        plt.ylabel('Percentatge (%)', fontsize=11)\n",
    "        plt.legend(title=target_col)\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.grid(True, alpha=0.3, axis='y')\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Valors An√≤mals o Absents\n",
    "\n",
    "Identifiquem i analitzem valors nuls i outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Valors Nuls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# An√†lisi de valors nuls\n",
    "print(\"An√†lisi de Valors Nuls:\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "missing_data = pd.DataFrame({\n",
    "    'Nombre de Nuls': df.isnull().sum(),\n",
    "    'Percentatge (%)': (df.isnull().sum() / len(df)) * 100\n",
    "}).sort_values(by='Nombre de Nuls', ascending=False)\n",
    "\n",
    "print(missing_data[missing_data['Nombre de Nuls'] > 0])\n",
    "\n",
    "if missing_data['Nombre de Nuls'].sum() == 0:\n",
    "    print(\"\\n‚úì No hi ha valors nuls al dataset!\")\n",
    "else:\n",
    "    print(f\"\\n‚ö†Ô∏è Total de valors nuls: {missing_data['Nombre de Nuls'].sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualitzaci√≥ de valors nuls\n",
    "if missing_data['Nombre de Nuls'].sum() > 0:\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    missing_cols = missing_data[missing_data['Nombre de Nuls'] > 0]\n",
    "    \n",
    "    plt.barh(missing_cols.index, missing_cols['Percentatge (%)'], color='coral')\n",
    "    plt.xlabel('Percentatge de Valors Nuls (%)', fontsize=12)\n",
    "    plt.ylabel('Variables', fontsize=12)\n",
    "    plt.title('Percentatge de Valors Nuls per Variable', fontweight='bold', fontsize=14)\n",
    "    plt.grid(True, alpha=0.3, axis='x')\n",
    "    \n",
    "    for i, v in enumerate(missing_cols['Percentatge (%)']):\n",
    "        plt.text(v + 0.5, i, f'{v:.1f}%', va='center')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Detecci√≥ d'Outliers (M√®tode IQR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detecci√≥ d'outliers utilitzant el m√®tode IQR (Interquartile Range)\n",
    "def detect_outliers_iqr(data, column):\n",
    "    \"\"\"\n",
    "    Detecta outliers utilitzant el m√®tode IQR.\n",
    "    Outliers s√≥n valors fora del rang [Q1 - 1.5*IQR, Q3 + 1.5*IQR]\n",
    "    \"\"\"\n",
    "    Q1 = data[column].quantile(0.25)\n",
    "    Q3 = data[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    \n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    \n",
    "    outliers = data[(data[column] < lower_bound) | (data[column] > upper_bound)]\n",
    "    \n",
    "    return outliers, lower_bound, upper_bound\n",
    "\n",
    "print(\"Detecci√≥ d'Outliers (M√®tode IQR):\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "outlier_summary = []\n",
    "\n",
    "for col in numeric_features:\n",
    "    outliers, lower, upper = detect_outliers_iqr(df, col)\n",
    "    n_outliers = len(outliers)\n",
    "    pct_outliers = (n_outliers / len(df)) * 100\n",
    "    \n",
    "    outlier_summary.append({\n",
    "        'Variable': col,\n",
    "        'Nombre Outliers': n_outliers,\n",
    "        'Percentatge (%)': round(pct_outliers, 2),\n",
    "        'L√≠mit Inferior': round(lower, 2),\n",
    "        'L√≠mit Superior': round(upper, 2)\n",
    "    })\n",
    "\n",
    "outlier_df = pd.DataFrame(outlier_summary)\n",
    "print(outlier_df)\n",
    "\n",
    "total_outliers = outlier_df['Nombre Outliers'].sum()\n",
    "print(f\"\\nTotal d'outliers detectats: {total_outliers}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualitzaci√≥ d'outliers amb box plots\n",
    "n_cols = 3\n",
    "n_rows = (len(numeric_features) + n_cols - 1) // n_cols\n",
    "\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(15, n_rows * 4))\n",
    "axes = axes.flatten() if n_rows > 1 else [axes]\n",
    "\n",
    "for idx, col in enumerate(numeric_features):\n",
    "    axes[idx].boxplot(df[col].dropna(), vert=True, patch_artist=True,\n",
    "                     boxprops=dict(facecolor='lightblue', alpha=0.7),\n",
    "                     medianprops=dict(color='red', linewidth=2))\n",
    "    axes[idx].set_title(f'Box Plot: {col}', fontweight='bold')\n",
    "    axes[idx].set_ylabel(col)\n",
    "    axes[idx].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Amagar eixos sobrants\n",
    "for idx in range(len(numeric_features), len(axes)):\n",
    "    axes[idx].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Propostes d'Acci√≥ per Valors An√≤mals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Propostes d'Acci√≥:\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Per valors nuls\n",
    "if missing_data['Nombre de Nuls'].sum() > 0:\n",
    "    print(\"\\nüìå VALORS NULS:\")\n",
    "    for col in missing_data[missing_data['Nombre de Nuls'] > 0].index:\n",
    "        pct = missing_data.loc[col, 'Percentatge (%)']\n",
    "        if pct < 5:\n",
    "            print(f\"  - {col}: Eliminar files ({pct:.1f}% de dades perdudes)\")\n",
    "        elif pct < 30:\n",
    "            if col in numeric_cols:\n",
    "                print(f\"  - {col}: Imputar amb mediana o mitjana ({pct:.1f}% de dades perdudes)\")\n",
    "            else:\n",
    "                print(f\"  - {col}: Imputar amb moda o categoria 'Unknown' ({pct:.1f}% de dades perdudes)\")\n",
    "        else:\n",
    "            print(f\"  - {col}: Considerar eliminar la variable ({pct:.1f}% de dades perdudes)\")\n",
    "\n",
    "# Per outliers\n",
    "if total_outliers > 0:\n",
    "    print(\"\\nüìå OUTLIERS:\")\n",
    "    for _, row in outlier_df[outlier_df['Nombre Outliers'] > 0].iterrows():\n",
    "        col = row['Variable']\n",
    "        pct = row['Percentatge (%)']\n",
    "        if pct < 1:\n",
    "            print(f\"  - {col}: Revisar manualment i considerar eliminaci√≥ ({pct:.1f}%)\")\n",
    "        elif pct < 5:\n",
    "            print(f\"  - {col}: Aplicar transformaci√≥ (log, sqrt) o winsoritzaci√≥ ({pct:.1f}%)\")\n",
    "        else:\n",
    "            print(f\"  - {col}: Poden ser valors leg√≠tims, revisar context cl√≠nic ({pct:.1f}%)\")\n",
    "\n",
    "if missing_data['Nombre de Nuls'].sum() == 0 and total_outliers == 0:\n",
    "    print(\"\\n‚úì No s'han detectat problemes significatius amb valors nuls o outliers.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. An√†lisi Bivariada i Correlacions\n",
    "\n",
    "Examinem les relacions entre variables i amb la variable objectiu."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 Matriu de Correlaci√≥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular matriu de correlaci√≥\n",
    "correlation_matrix = df[numeric_cols].corr()\n",
    "\n",
    "# Visualitzaci√≥ de la matriu de correlaci√≥\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(correlation_matrix, annot=True, fmt='.2f', cmap='coolwarm', \n",
    "            center=0, square=True, linewidths=1, cbar_kws={\"shrink\": 0.8})\n",
    "plt.title('Matriu de Correlaci√≥ de Variables Num√®riques', fontweight='bold', fontsize=14, pad=20)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Correlacions amb la Variable Objectiu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlacions amb la variable objectiu\n",
    "if target_col in numeric_cols:\n",
    "    target_correlations = correlation_matrix[target_col].drop(target_col).sort_values(ascending=False)\n",
    "    \n",
    "    print(\"Correlacions amb la Variable Objectiu:\")\n",
    "    print(\"=\"*80)\n",
    "    print(target_correlations)\n",
    "    \n",
    "    # Visualitzaci√≥\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    colors = ['green' if x > 0 else 'red' for x in target_correlations]\n",
    "    target_correlations.plot(kind='barh', color=colors, edgecolor='black')\n",
    "    plt.title(f'Correlaci√≥ de Variables amb {target_col}', fontweight='bold', fontsize=14)\n",
    "    plt.xlabel('Coeficient de Correlaci√≥', fontsize=12)\n",
    "    plt.ylabel('Variables', fontsize=12)\n",
    "    plt.axvline(x=0, color='black', linestyle='--', linewidth=0.8)\n",
    "    plt.grid(True, alpha=0.3, axis='x')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Identificar correlacions fortes\n",
    "    strong_corr = target_correlations[abs(target_correlations) > 0.5]\n",
    "    if len(strong_corr) > 0:\n",
    "        print(\"\\nüìå Variables amb correlaci√≥ FORTA (|r| > 0.5):\")\n",
    "        for var, corr in strong_corr.items():\n",
    "            print(f\"  - {var}: {corr:.3f}\")\n",
    "    else:\n",
    "        print(\"\\n‚ö†Ô∏è No s'han trobat correlacions fortes amb la variable objectiu.\")\n",
    "else:\n",
    "    print(f\"La variable objectiu '{target_col}' no √©s num√®rica. Utilitzarem altres m√®todes d'an√†lisi.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3 Detecci√≥ de Multicolinealitat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identificar parelles de variables amb alta correlaci√≥ (possibles redund√†ncies)\n",
    "print(\"Detecci√≥ de Multicolinealitat:\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Crear una m√†scara per la meitat superior de la matriu\n",
    "upper_triangle = np.triu(np.ones_like(correlation_matrix, dtype=bool), k=1)\n",
    "\n",
    "# Trobar parelles amb correlaci√≥ alta\n",
    "high_corr_pairs = []\n",
    "for i in range(len(correlation_matrix.columns)):\n",
    "    for j in range(i+1, len(correlation_matrix.columns)):\n",
    "        if abs(correlation_matrix.iloc[i, j]) > 0.7:  # Llindar de 0.7\n",
    "            high_corr_pairs.append({\n",
    "                'Variable 1': correlation_matrix.columns[i],\n",
    "                'Variable 2': correlation_matrix.columns[j],\n",
    "                'Correlaci√≥': round(correlation_matrix.iloc[i, j], 3)\n",
    "            })\n",
    "\n",
    "if high_corr_pairs:\n",
    "    high_corr_df = pd.DataFrame(high_corr_pairs).sort_values(by='Correlaci√≥', \n",
    "                                                              key=abs, ascending=False)\n",
    "    print(\"\\n‚ö†Ô∏è Parelles de variables amb ALTA correlaci√≥ (|r| > 0.7):\")\n",
    "    print(high_corr_df.to_string(index=False))\n",
    "    print(\"\\nüí° Recomanaci√≥: Considerar eliminar una de les variables de cada parella per evitar redund√†ncia.\")\n",
    "else:\n",
    "    print(\"\\n‚úì No s'ha detectat multicolinealitat significativa entre variables.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.4 An√†lisi de Variables Categ√≤riques vs Objectiu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test de Chi-quadrat per variables categ√≤riques\n",
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "print(\"An√†lisi d'Associaci√≥: Variables Categ√≤riques vs Variable Objectiu\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "chi2_results = []\n",
    "\n",
    "for col in categorical_cols:\n",
    "    if col != target_col:\n",
    "        # Crear taula de conting√®ncia\n",
    "        contingency_table = pd.crosstab(df[col], df[target_col])\n",
    "        \n",
    "        # Test de Chi-quadrat\n",
    "        chi2, p_value, dof, expected = chi2_contingency(contingency_table)\n",
    "        \n",
    "        chi2_results.append({\n",
    "            'Variable': col,\n",
    "            'Chi-quadrat': round(chi2, 3),\n",
    "            'p-valor': round(p_value, 4),\n",
    "            'Significativa': 'S√≠' if p_value < 0.05 else 'No'\n",
    "        })\n",
    "\n",
    "if chi2_results:\n",
    "    chi2_df = pd.DataFrame(chi2_results).sort_values(by='p-valor')\n",
    "    print(chi2_df.to_string(index=False))\n",
    "    \n",
    "    significant_vars = chi2_df[chi2_df['Significativa'] == 'S√≠']\n",
    "    if len(significant_vars) > 0:\n",
    "        print(f\"\\nüìå {len(significant_vars)} variable(s) categ√≤rica(es) mostren associaci√≥ significativa amb {target_col} (p < 0.05)\")\n",
    "    else:\n",
    "        print(f\"\\n‚ö†Ô∏è Cap variable categ√≤rica mostra associaci√≥ significativa amb {target_col}\")\n",
    "else:\n",
    "    print(\"No hi ha variables categ√≤riques per analitzar (a part de la variable objectiu).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.5 Comparaci√≥ de Mitjanes entre Grups (T-test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# T-test per comparar mitjanes entre grups\n",
    "from scipy.stats import ttest_ind\n",
    "\n",
    "print(\"Comparaci√≥ de Mitjanes entre Grups (T-test):\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Assumim que la variable objectiu √©s bin√†ria\n",
    "groups = df[target_col].unique()\n",
    "\n",
    "if len(groups) == 2:\n",
    "    group1_data = df[df[target_col] == groups[0]]\n",
    "    group2_data = df[df[target_col] == groups[1]]\n",
    "    \n",
    "    ttest_results = []\n",
    "    \n",
    "    for col in numeric_features:\n",
    "        # Eliminar valors nuls\n",
    "        g1 = group1_data[col].dropna()\n",
    "        g2 = group2_data[col].dropna()\n",
    "        \n",
    "        if len(g1) > 0 and len(g2) > 0:\n",
    "            t_stat, p_value = ttest_ind(g1, g2)\n",
    "            \n",
    "            ttest_results.append({\n",
    "                'Variable': col,\n",
    "                f'Mitjana Grup {groups[0]}': round(g1.mean(), 2),\n",
    "                f'Mitjana Grup {groups[1]}': round(g2.mean(), 2),\n",
    "                'Difer√®ncia': round(g2.mean() - g1.mean(), 2),\n",
    "                't-statistic': round(t_stat, 3),\n",
    "                'p-valor': round(p_value, 4),\n",
    "                'Significativa': 'S√≠' if p_value < 0.05 else 'No'\n",
    "            })\n",
    "    \n",
    "    if ttest_results:\n",
    "        ttest_df = pd.DataFrame(ttest_results).sort_values(by='p-valor')\n",
    "        print(ttest_df.to_string(index=False))\n",
    "        \n",
    "        significant_diffs = ttest_df[ttest_df['Significativa'] == 'S√≠']\n",
    "        if len(significant_diffs) > 0:\n",
    "            print(f\"\\nüìå {len(significant_diffs)} variable(s) mostren difer√®ncies significatives entre grups (p < 0.05)\")\n",
    "        else:\n",
    "            print(\"\\n‚ö†Ô∏è Cap variable mostra difer√®ncies significatives entre grups\")\n",
    "else:\n",
    "    print(f\"La variable objectiu t√© {len(groups)} categories. T-test nom√©s √©s aplicable per 2 grups.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Resum de Descobertes\n",
    "\n",
    "Sintetitzem les conclusions clau de l'an√†lisi explorat√≤ria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"RESUM DE DESCOBERTES CLAU\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "discoveries = []\n",
    "\n",
    "# 1. Equilibri de classes\n",
    "if 'imbalance_ratio' in locals():\n",
    "    if imbalance_ratio > 2:\n",
    "        discoveries.append(\n",
    "            f\"1Ô∏è‚É£ DESEQUILIBRI DE CLASSES: El dataset presenta un desequilibri significatiu \"\n",
    "            f\"({imbalance_ratio:.1f}:1). Caldr√† aplicar t√®cniques de balanceig (SMOTE, undersampling, etc.) \"\n",
    "            f\"o utilitzar m√®triques adequades (F1-score, AUC-ROC) en lloc d'accuracy.\"\n",
    "        )\n",
    "    else:\n",
    "        discoveries.append(\n",
    "            f\"1Ô∏è‚É£ EQUILIBRI DE CLASSES: El dataset est√† relativament equilibrat ({imbalance_ratio:.1f}:1), \"\n",
    "            f\"la qual cosa facilita l'entrenament de models.\"\n",
    "        )\n",
    "\n",
    "# 2. Valors nuls i qualitat de dades\n",
    "total_missing = missing_data['Nombre de Nuls'].sum()\n",
    "if total_missing > 0:\n",
    "    pct_missing = (total_missing / (len(df) * len(df.columns))) * 100\n",
    "    discoveries.append(\n",
    "        f\"2Ô∏è‚É£ QUALITAT DE DADES: S'han detectat {total_missing} valors nuls ({pct_missing:.1f}% del dataset). \"\n",
    "        f\"Les variables m√©s afectades s√≥n: {', '.join(missing_data[missing_data['Nombre de Nuls'] > 0].head(3).index.tolist())}. \"\n",
    "        f\"Es recomana imputaci√≥ o eliminaci√≥ segons el percentatge de dades perdudes.\"\n",
    "    )\n",
    "else:\n",
    "    discoveries.append(\n",
    "        \"2Ô∏è‚É£ QUALITAT DE DADES: El dataset no cont√© valors nuls, la qual cosa indica una bona qualitat de dades.\"\n",
    "    )\n",
    "\n",
    "# 3. Outliers\n",
    "if 'total_outliers' in locals() and total_outliers > 0:\n",
    "    pct_outliers = (total_outliers / len(df)) * 100\n",
    "    top_outlier_vars = outlier_df.nlargest(3, 'Nombre Outliers')['Variable'].tolist()\n",
    "    discoveries.append(\n",
    "        f\"3Ô∏è‚É£ OUTLIERS: S'han detectat {total_outliers} outliers ({pct_outliers:.1f}% de les observacions). \"\n",
    "        f\"Les variables amb m√©s outliers s√≥n: {', '.join(top_outlier_vars)}. \"\n",
    "        f\"Cal revisar si s√≥n errors o valors leg√≠tims abans d'aplicar transformacions.\"\n",
    "    )\n",
    "else:\n",
    "    discoveries.append(\n",
    "        \"3Ô∏è‚É£ OUTLIERS: No s'han detectat outliers significatius utilitzant el m√®tode IQR.\"\n",
    "    )\n",
    "\n",
    "# 4. Correlacions i relacions\n",
    "if target_col in numeric_cols and 'strong_corr' in locals():\n",
    "    if len(strong_corr) > 0:\n",
    "        top_corr_var = strong_corr.abs().idxmax()\n",
    "        top_corr_val = strong_corr[top_corr_var]\n",
    "        discoveries.append(\n",
    "            f\"4Ô∏è‚É£ PREDICTORS RELLEVANTS: S'han identificat {len(strong_corr)} variable(s) amb correlaci√≥ forta \"\n",
    "            f\"amb la variable objectiu. La m√©s rellevant √©s '{top_corr_var}' (r={top_corr_val:.3f}). \"\n",
    "            f\"Aquestes variables seran clau per al modelatge predictiu.\"\n",
    "        )\n",
    "    else:\n",
    "        discoveries.append(\n",
    "            \"4Ô∏è‚É£ PREDICTORS RELLEVANTS: No s'han trobat correlacions lineals fortes amb la variable objectiu. \"\n",
    "            \"Pot ser necessari explorar relacions no lineals o interaccions entre variables.\"\n",
    "        )\n",
    "\n",
    "# 5. Multicolinealitat\n",
    "if 'high_corr_pairs' in locals() and len(high_corr_pairs) > 0:\n",
    "    discoveries.append(\n",
    "        f\"5Ô∏è‚É£ MULTICOLINEALITAT: S'han detectat {len(high_corr_pairs)} parella(es) de variables amb alta correlaci√≥. \"\n",
    "        f\"Es recomana eliminar variables redundants per millorar la interpretabilitat del model i evitar problemes \"\n",
    "        f\"en models lineals.\"\n",
    "    )\n",
    "else:\n",
    "    discoveries.append(\n",
    "        \"5Ô∏è‚É£ MULTICOLINEALITAT: No s'ha detectat multicolinealitat significativa entre predictors.\"\n",
    "    )\n",
    "\n",
    "# Imprimir descobertes\n",
    "for discovery in discoveries:\n",
    "    print(f\"\\n{discovery}\")\n",
    "    print(\"-\" * 80)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"CONCLUSIONS I RECOMANACIONS PER AL MODELATGE\")\n",
    "print(\"=\"*80)\n",
    "print(\"\"\"\n",
    "Basant-nos en l'an√†lisi explorat√≤ria realitzada, es recomana:\n",
    "\n",
    "üìã PREPROCESSAMENT:\n",
    "   ‚Ä¢ Tractar valors nuls mitjan√ßant imputaci√≥ o eliminaci√≥ segons el cas\n",
    "   ‚Ä¢ Revisar i tractar outliers (transformacions, winsoritzaci√≥ o eliminaci√≥)\n",
    "   ‚Ä¢ Normalitzar/estandarditzar variables num√®riques si cal\n",
    "   ‚Ä¢ Codificar variables categ√≤riques (one-hot encoding, label encoding)\n",
    "\n",
    "üéØ SELECCI√ì DE CARACTER√çSTIQUES:\n",
    "   ‚Ä¢ Prioritzar variables amb correlaci√≥ forta amb la variable objectiu\n",
    "   ‚Ä¢ Eliminar variables redundants (alta multicolinealitat)\n",
    "   ‚Ä¢ Considerar enginyeria de caracter√≠stiques (interaccions, transformacions)\n",
    "\n",
    "‚öñÔ∏è BALANCEIG DE CLASSES (si cal):\n",
    "   ‚Ä¢ Aplicar SMOTE, ADASYN o altres t√®cniques de sobremuestreig\n",
    "   ‚Ä¢ Considerar submuestreig de la classe majorit√†ria\n",
    "   ‚Ä¢ Utilitzar pesos de classe en l'entrenament del model\n",
    "\n",
    "üìä VALIDACI√ì I M√àTRIQUES:\n",
    "   ‚Ä¢ Utilitzar validaci√≥ creuada estratificada\n",
    "   ‚Ä¢ Prioritzar m√®triques adequades: F1-score, AUC-ROC, Precision-Recall\n",
    "   ‚Ä¢ Analitzar matriu de confusi√≥ per entendre errors del model\n",
    "\"\"\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusi√≥\n",
    "\n",
    "Aquest notebook ha completat una an√†lisi explorat√≤ria exhaustiva del dataset de dem√®ncia, cobrint:\n",
    "\n",
    "‚úÖ C√†rrega i inspecci√≥ inicial del dataset  \n",
    "‚úÖ An√†lisi de la distribuci√≥ de la variable objectiu  \n",
    "‚úÖ Estad√≠stiques descriptives univariants  \n",
    "‚úÖ Visualitzacions comprehensives (histogrames, box plots, scatter plots)  \n",
    "‚úÖ Detecci√≥ i an√†lisi de valors nuls i outliers  \n",
    "‚úÖ An√†lisi bivariada i correlacions  \n",
    "‚úÖ S√≠ntesi de descobertes clau i recomanacions  \n",
    "\n",
    "Els resultats d'aquesta EDA proporcionen una base s√≤lida per a les seg√ºents fases del projecte:\n",
    "- Preprocessament de dades\n",
    "- Enginyeria de caracter√≠stiques\n",
    "- Selecci√≥ de models\n",
    "- Entrenament i validaci√≥\n",
    "\n",
    "---\n",
    "\n",
    "**Pr√≤xims passos suggerits:**\n",
    "1. Implementar el pipeline de preprocessament basat en les descobertes\n",
    "2. Crear noves caracter√≠stiques rellevants\n",
    "3. Experimentar amb diferents algoritmes de machine learning\n",
    "4. Optimitzar hiperpar√†metres dels models seleccionats\n",
    "5. Avaluar i comparar el rendiment dels models"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
